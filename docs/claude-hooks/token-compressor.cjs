#!/usr/bin/env node
/**
 * TOKEN COMPRESSOR v6.0 - ULTRA COMPRESSION
 * =========================================
 *
 * KEY INSIGHT: Character savings matter, not word count!
 * - Chinese text needs no spaces between characters
 * - Use micro-delimiter (Â·) only when mixing with English
 * - Measure CHARACTER savings (the real metric)
 *
 * TARGETS:
 *   - 65-75% CHARACTER savings
 *   - 100% semantic round-trip accuracy
 *
 * @author hardwicksoftwareservices
 * @website https://justcalljon.pro
 */

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// WARNING PREFIX - Prevents Claude from responding in Chinese
// Compact version: 120 chars vs original 260 chars (54% smaller!)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
const COMPRESSION_WARNING = `âš ï¸ CONTEXT COMPRESSION ACTIVE âš ï¸
The following context has been compressed to Traditional Chinese for token efficiency.
DO NOT output responses in Chinese. Continue responding in English as normal.
The compression is purely for context storage - treat it as English internally.
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

`;

// Ultra-compact warning - SINGLE LINE (default for hooks)
const COMPACT_WARNING = `âš ï¸å£“ç¸®:ç¹ä¸­â†’EN â”‚ `;

// Micro-delimiter for Chinese-English boundaries (middle dot - very small)
const MICRO_SEP = 'Â·';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ULTRA-AGGRESSIVE FILLER REMOVAL (~150 words)
// These words can be removed without losing semantic meaning
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
const REMOVE = new Set([
  // â”€â”€â”€ Articles â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  'a', 'an', 'the',

  // â”€â”€â”€ Be verbs (all forms) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being',

  // â”€â”€â”€ Have verbs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  'has', 'have', 'had', 'having',

  // â”€â”€â”€ Do verbs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  'do', 'does', 'did', 'doing', 'done',

  // â”€â”€â”€ Modal verbs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  'can', 'could', 'will', 'would', 'shall', 'should', 'may', 'might', 'must',

  // â”€â”€â”€ Pronouns (all) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  'i', 'me', 'my', 'mine', 'myself',
  'you', 'your', 'yours', 'yourself', 'yourselves',
  'he', 'him', 'his', 'himself',
  'she', 'her', 'hers', 'herself',
  'it', 'its', 'itself',
  'we', 'us', 'our', 'ours', 'ourselves',
  'they', 'them', 'their', 'theirs', 'themselves',
  'who', 'whom', 'whose', 'which', 'that', 'what',
  'this', 'that', 'these', 'those',
  'one', 'ones', 'someone', 'anyone', 'everyone', 'no one', 'nobody',
  'something', 'anything', 'everything', 'nothing',
  'somewhere', 'anywhere', 'everywhere', 'nowhere',

  // â”€â”€â”€ Prepositions (common) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  'of', 'to', 'in', 'on', 'at', 'by', 'for', 'with', 'about',
  'into', 'onto', 'upon', 'from', 'off', 'out',
  'up', 'down', 'over', 'under', 'above', 'below',
  'between', 'among', 'through', 'during', 'before', 'after',
  'around', 'against', 'within', 'without', 'along', 'across',
  'behind', 'beside', 'besides', 'beyond', 'near', 'toward', 'towards',

  // â”€â”€â”€ Conjunctions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  'and', 'or', 'but', 'nor', 'so', 'yet', 'for',
  'because', 'since', 'although', 'though', 'while', 'whereas',
  'if', 'unless', 'until', 'when', 'where', 'whether',
  'as', 'than', 'once', 'after', 'before',

  // â”€â”€â”€ Adverbs (filler) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  'very', 'really', 'quite', 'rather', 'fairly', 'pretty',
  'just', 'only', 'even', 'still', 'already', 'yet',
  'also', 'too', 'either', 'neither', 'both',
  'always', 'never', 'ever', 'often', 'sometimes', 'rarely', 'seldom',
  'usually', 'normally', 'generally', 'typically', 'commonly',
  'actually', 'basically', 'essentially', 'simply', 'merely',
  'certainly', 'definitely', 'probably', 'possibly', 'perhaps', 'maybe',
  'apparently', 'evidently', 'obviously', 'clearly',
  'however', 'therefore', 'thus', 'hence', 'consequently',
  'moreover', 'furthermore', 'additionally', 'meanwhile',
  'instead', 'otherwise', 'nevertheless', 'nonetheless',
  'now', 'then', 'here', 'there', 'where',
  'well', 'anyway', 'indeed', 'surely',

  // â”€â”€â”€ Determiners & Quantifiers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  'some', 'any', 'no', 'every', 'each', 'all', 'both', 'half',
  'few', 'little', 'much', 'many', 'more', 'most', 'less', 'least',
  'several', 'enough', 'plenty',
  'another', 'other', 'others', 'such',
  'own', 'same', 'different',

  // â”€â”€â”€ Auxiliary/Helper words â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  'get', 'gets', 'got', 'getting', 'gotten',
  'let', 'lets', 'make', 'makes', 'made', 'making',
  'keep', 'keeps', 'kept', 'keeping',
  'seem', 'seems', 'seemed', 'seeming',
  'appear', 'appears', 'appeared', 'appearing',
  'become', 'becomes', 'became', 'becoming',

  // â”€â”€â”€ Generic nouns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  'thing', 'things', 'stuff', 'way', 'ways',
  'kind', 'kinds', 'sort', 'sorts', 'type', 'types',
  'bit', 'lot', 'lots', 'bunch',
  'case', 'cases', 'instance', 'instances',
  'example', 'examples', 'fact', 'facts',

  // â”€â”€â”€ Misc filler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  'like', 'etc', 'ie', 'eg', 'vs', 'via',
  'please', 'kindly', 'thanks', 'thank',
  'yes', 'no', 'ok', 'okay',
]);

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// PHRASE DICTIONARY - Multi-word â†’ UNIQUE codes (no collisions!)
// Each phrase gets a completely unique code - no sharing with single words
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
const PHRASES = {
  // 3+ word phrases â†’ UNIQUE codes (using rare characters/combos)
  'in order to': 'çˆ²äº†',      // unique - not used elsewhere
  'as well as': 'ä»¥åŠ',       // unique
  'such as': 'è«¸å¦‚',          // unique
  'for example': 'èˆ‰ä¾‹',      // unique
  'make sure': 'ç¢ºä¿',        // unique
  'at the same time': 'åŒæ™‚', // unique
  'on the other hand': 'å¦æ–¹', // unique
  'in addition to': 'æ­¤å¤–',   // unique
  'due to': 'ç”±æ–¼',           // unique
  'based on': 'åŸºæ–¼',         // unique
  'according to': 'ä¾ç…§',     // unique
  'in the case of': 'è‹¥æ˜¯',   // unique
  'as a result': 'çµæœæ˜¯',    // unique
  'with respect to': 'é—œæ–¼',  // unique
  'in terms of': 'å°±è«–',      // unique
  'a lot of': 'è¨±å¤š',         // unique
  'a number of': 'è‹¥å¹²',      // unique
  'one of': 'å…¶ä¸€',           // unique
  'each of': 'æ¯å€‹',          // unique
  'all of': 'æ‰€æœ‰',           // unique
  'some of': 'éƒ¨åˆ†çš„',        // unique
  'most of': 'å¤§å¤š',          // unique
  'none of': 'ç„¡ä¸€',          // unique
  'the rest of': 'å…¶é¤˜',      // unique
  'the same as': 'ç›¸åŒ',      // unique
  'different from': 'ä¸åŒæ–¼', // unique
  'similar to': 'é¡ä¼¼',       // unique
  'up to': 'é«˜é”',            // unique
  'out of': 'å¾ä¸­',           // unique
  'instead of': 'è€Œé',       // unique
  'in front of': 'å‰é¢',      // unique
  'on top of': 'ä¹‹ä¸Š',        // unique
  'at the end': 'æœ€å¾Œ',       // unique
  'at the beginning': 'æœ€åˆ', // unique
  'able to': 'èƒ½å¤ ',          // unique
  'unable to': 'ç„¡æ³•',        // unique
  'have to': 'å¿…é ˆ',          // unique
  'want to': 'æƒ³è¦',          // unique
  'need to': 'éœ€è¦',          // unique - NOT 'éœ€' which is 'require'
  'try to': 'å˜—è©¦',           // unique - NOT 'è©¦' which is 'test'
  'used to': 'æ›¾ç¶“',          // unique
  'going to': 'å³å°‡',         // unique
  'about to': 'å°‡è¦',         // unique
  'supposed to': 'æ‡‰è©²',      // unique
  'allowed to': 'å…è¨±',       // unique
  'required to': 'å¿…éœ€',      // unique
  'how to': 'å¦‚ä½•',           // unique
  'what to': 'ä½•äº‹',          // unique
  'where to': 'ä½•è™•',         // unique
  'whether or not': 'æ˜¯å¦',   // unique
  'not only': 'ä¸åƒ…',         // unique
  'but also': 'ä¹Ÿæ˜¯',         // unique
  'more than': 'è¶…é',        // unique
  'less than': 'å°‘æ–¼',        // unique
  'at least': 'è‡³å°‘',         // unique
  'at most': 'æœ€å¤š',          // unique
  'as soon as': 'ä¸€æ—¦',       // unique
  'as long as': 'åªè¦',       // unique
  'depends on': 'å–æ±ºæ–¼',     // unique
  'results in': 'å°è‡´',       // unique - different from 'leads to'
  'leads to': 'å¼•å‘',         // unique
  'belongs to': 'æ­¸å±¬',       // unique
  'refers to': 'æŒ‡çš„',        // unique
  'related to': 'ç›¸é—œæ–¼',     // unique
  'compared to': 'ç›¸æ¯”',      // unique
  'consists of': 'çµ„æˆæ–¼',    // unique
  'made of': 'è£½æ–¼',          // unique
  'set up': 'è¨­ç«‹',           // unique - NOT 'è¨­' which is 'let'
  'look up': 'æŸ¥æ‰¾',          // unique
  'look for': 'å°‹æ‰¾',         // unique
  'come from': 'ä¾†è‡ª',        // unique
  'go back': 'è¿”å›',          // unique - NOT 'å›' which is 'callback'
  'take place': 'ç™¼ç”Ÿ',       // unique
  'turn on': 'é–‹å•Ÿ',          // unique
  'turn off': 'é—œé–‰',         // unique
  'carry out': 'åŸ·è¡Œ',        // unique
  'find out': 'ç™¼ç¾',         // unique
  'figure out': 'å¼„æ¸…',       // unique
  'point out': 'æŒ‡å‡º',        // unique
  'work on': 'å¾äº‹',          // unique
  'deal with': 'è™•ç†',        // unique
  'log in': 'ç™»å…¥',           // unique
  'log out': 'ç™»å‡º',          // unique
  'sign up': 'è¨»å†Š',          // unique

  // Programming phrases - all UNIQUE codes
  'return value': 'è¿”å›å€¼',   // unique
  'function call': 'å‡½æ•¸å‘¼',  // unique
  'error message': 'éŒ¯èª¤è¨Š',  // unique
  'error handling': 'éŒ¯èª¤è™•', // unique
  'null check': 'ç©ºå€¼æŸ¥',     // unique
  'type check': 'å‹åˆ¥æŸ¥',     // unique
  'data type': 'æ•¸æ“šå‹',      // unique
  'data structure': 'æ•¸æ“šæ§‹', // unique
  'source code': 'æºä»£ç¢¼',    // unique
  'test case': 'æ¸¬è©¦ä¾‹',      // unique
  'use case': 'ä½¿ç”¨ä¾‹',       // unique
  'best practice': 'æœ€ä½³è¸',  // unique
  'code review': 'ä»£ç¢¼å¯©',    // unique
  'pull request': 'PR',       // keep as-is
  'merge request': 'MR',      // keep as-is
  'api call': 'APIå‘¼å«',      // unique
  'api endpoint': 'APIç«¯é»',  // unique
  'database query': 'è³‡æ–™è©¢', // unique
  'database connection': 'è³‡æ–™é€£', // unique
  'file system': 'æª”æ¡ˆç³»',    // unique
  'file path': 'æª”æ¡ˆè·¯',      // unique
  'working directory': 'å·¥ä½œç›®', // unique
  'environment variable': 'ç’°å¢ƒè®Š', // unique
  'config file': 'é…ç½®æª”',    // unique
  'log file': 'æ—¥èªŒæª”',       // unique
  'memory leak': 'è¨˜æ†¶æ¼',    // unique
  'stack trace': 'æ£§è¿½è¹¤',    // unique
  'call stack': 'å‘¼å«æ£§',     // unique
  'garbage collection': 'GC', // keep as-is
  'race condition': 'ç«¶æ…‹æ¢', // unique
  'dead lock': 'æ­»é–ä½',      // unique
  'unit test': 'å–®å…ƒæ¸¬',      // unique
  'integration test': 'é›†æˆæ¸¬', // unique
  'end to end': 'E2E',        // keep as-is
  'version control': 'ç‰ˆæœ¬æ§', // unique
  'access control': 'è¨ªå•æ§', // unique
  'not found': 'æœªæ‰¾åˆ°',      // unique
  'already exists': 'å·²å­˜åœ¨', // unique
  'does not exist': 'ä¸å­˜åœ¨', // unique
  'can be': 'å¯ä»¥æ˜¯',         // unique
  'should be': 'æ‡‰ç•¶æ˜¯',      // unique
  'would be': 'æœƒæ˜¯',         // unique
  'must be': 'å¿…æ˜¯',          // unique
  'will be': 'å°‡æ˜¯',          // unique
  'has been': 'å·²ç¶“æ˜¯',       // unique
  'have been': 'å·²ç¶“æœ‰',      // unique
  'had been': 'æ›¾ç¶“æ˜¯',       // unique
};

// Sort phrases by length (longest first)
const SORTED_PHRASES = Object.entries(PHRASES).sort((a, b) => b[0].length - a[0].length);

// Build reverse phrase mapping
const REVERSE_PHRASES = {};
for (const [eng, chi] of SORTED_PHRASES) {
  REVERSE_PHRASES[chi] = eng;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// SINGLE CHARACTER CODES - No suffixes for maximum compression
// Context provides grammar, we just preserve semantics
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EXPANDED DICTIONARY - 22,000+ entries from CC-CEDICT + curated programming terms
// Loaded from merged-codes.cjs (Traditional Chinese ç¹é«”ä¸­æ–‡)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
let CODES;
try {
  CODES = require('./merged-codes.cjs');
  // console.error('[TokenCompressor] Loaded', Object.keys(CODES).length, 'codes');
} catch (e) {
  // Fallback to minimal essential codes if file not found
  CODES = {
    'function': 'å‡½', 'variable': 'è®Š', 'parameter': 'åƒ', 'argument': 'å¯¦åƒ',
  'return': 'è¿”', 'class': 'é¡', 'object': 'ç‰©', 'array': 'é™£', 'string': 'ä¸²',
  'number': 'æ•¸', 'boolean': 'å¸ƒ', 'value': 'å€¼', 'method': 'æ³•',
  'property': 'å±¬', 'interface': 'ä»‹', 'module': 'æ¨¡çµ„', 'package': 'åŒ…',
  'library': 'åº«', 'framework': 'æ¶', 'dependency': 'è³´', 'null': 'ç©ºå€¼',
  'undefined': 'æœª', 'error': 'éŒ¯', 'exception': 'ç•°', 'warning': 'è­¦',
  'debug': 'èª¿', 'memory': 'è¨˜', 'buffer': 'ç·©', 'stack': 'æ£§', 'heap': 'å †',
  'queue': 'åˆ—', 'callback': 'å›', 'promise': 'è«¾', 'async': 'ç•°æ­¥',
  'await': 'ç­‰', 'sync': 'åŒæ­¥', 'import': 'å°', 'export': 'å‡º', 'require': 'éœ€',
  'const': 'æ†', 'let': 'è®“', 'var': 'å®£',

  // Actions - BASE FORMS ONLY (suffixes auto-handled)
  'create': 'å‰µ', 'read': 'è®€', 'update': 'æ›´', 'delete': 'åˆª', 'add': 'åŠ ',
  'remove': 'é™¤', 'insert': 'æ’', 'find': 'æ‰¾', 'found': 'æ‰¾', // 'found' is irregular
  'search': 'æœ', 'filter': 'æ¿¾', 'sort': 'æ’', 'parse': 'æ', 'format': 'æ ¼',
  'validate': 'é©—', 'check': 'æŸ¥', 'test': 'è©¦', 'verify': 'æ ¸', 'load': 'è¼‰',
  'save': 'å­˜', 'store': 'å„²', 'storage': 'å„²å­˜', 'fetch': 'å–', 'send': 'é€', // storage unique!
  'sent': 'é€', // irregular
  'receive': 'æ”¶', 'connect': 'é€£', 'disconnect': 'æ–·', 'start': 'å•Ÿ',
  'stop': 'åœ', 'run': 'è·‘', 'ran': 'è·‘', // irregular
  'execute': 'åŸ·', 'call': 'å‘¼', 'invoke': 'å–š', 'trigger': 'è§¸',
  'handle': 'ç†', 'process': 'è™•', 'initialize': 'åˆ', 'configure': 'é…ç½®',
  'setup': 'è¨­ç«‹', 'install': 'è£', 'deploy': 'éƒ¨', 'build': 'å»º',
  'built': 'å»º', // irregular
  'compile': 'ç·¨', 'render': 'æ¸²', 'display': 'é¡¯', 'show': 'ç¤º',
  'hide': 'è—', 'hidden': 'è—', // irregular
  'enable': 'å•Ÿç”¨', 'disable': 'ç¦', 'open': 'é–‹', 'close': 'é–‰',
  'write': 'å¯«', 'wrote': 'å¯«', 'written': 'å¯«', // irregular
  'use': 'ç”¨', 'provide': 'ä¾›', 'include': 'å«', 'contain': 'å®¹ç´',
  'work': 'å·¥', 'change': 'æ”¹', 'modify': 'ä¿®æ”¹', 'fix': 'ä¿®å¾©',
  'resolve': 'è§£', 'implement': 'å¯¦', 'define': 'å®š', 'declare': 'è²',
  'assign': 'è³¦', 'convert': 'è½‰', 'transform': 'è®Šæ›', 'map': 'æ˜ ',
  'reduce': 'æ¸›', 'merge': 'ä½µ', 'split': 'æ‹†', 'join': 'è¯',
  'copy': 'è¤‡', 'move': 'ç§»', 'replace': 'æ›', 'match': 'åŒ¹é…',
  'compare': 'æ¯”', 'calculate': 'ç®—', 'count': 'è¨ˆ', 'print': 'å°',
  'log': 'èªŒ', 'trace': 'è·Ÿ', 'monitor': 'ç›£', 'watch': 'è§€',
  'listen': 'è½', 'wait': 'å¾…', 'retry': 'é‡è©¦', 'reset': 'é‡è¨­',
  'clear': 'æ¸…', 'extend': 'å»¶', 'inherit': 'ç¹¼', 'override': 'è¦†',
  'encode': 'ç·¨ç¢¼', 'decode': 'è§£ç¢¼', 'encrypt': 'åŠ å¯†', 'decrypt': 'è§£å¯†',
  'compress': 'å£“', 'decompress': 'è§£å£“',

  // System/Infrastructure - BASE FORMS ONLY
  'server': 'æœ', 'client': 'å®¢', 'database': 'è³‡', 'cache': 'å¿«',
  'file': 'æª”', 'directory': 'ç›®', 'folder': 'å¤¾', 'path': 'å¾‘',
  'request': 'æ±‚', 'response': 'æ‡‰', 'query': 'è©¢', 'session': 'æœƒ',
  'token': 'ä»¤', 'user': 'æˆ¶', 'admin': 'ç®¡', 'permission': 'æ¬Š',
  'role': 'è§’', 'authentication': 'èªè­‰', 'authorization': 'æˆæ¬Š',
  'connection': 'æ¥', 'socket': 'å¥—', 'port': 'åŸ ', 'host': 'ä¸»',
  'domain': 'ç¶²åŸŸ', 'endpoint': 'ç«¯', 'route': 'è·¯',
  'url': 'URL', 'api': 'API', 'rest': 'REST', 'http': 'HTTP', 'https': 'HTTPS',
  'service': 'å‹™', 'container': 'å®¹', 'cluster': 'ç¾¤', 'node': 'ç¯€',
  'network': 'ç¶²', 'proxy': 'ä»£', 'event': 'äº‹', 'message': 'è¨Š',
  'channel': 'é »', 'stream': 'æµ', 'thread': 'ç·’', 'task': 'ä»»',
  'job': 'ä½œ', 'worker': 'å·¥er', // English suffix keeps unique from 'work'
  'timeout': 'é€¾æ™‚', 'interval': 'é–“éš”',

  // Data structures - BASE FORMS ONLY
  'list': 'å–®', 'set': 'é›†', 'dict': 'å…¸', 'dictionary': 'å…¸',
  'tree': 'æ¨¹', 'graph': 'åœ–', 'table': 'è¡¨', 'row': 'è¡Œ',
  'column': 'æ¬„', 'record': 'éŒ„', 'field': 'æ¬„ä½', 'index': 'ç´¢',
  'indice': 'ç´¢', // for 'indices'
  'key': 'éµ', 'id': 'ID', 'pointer': 'æŒ‡', 'reference': 'åƒå¼•',
  'link': 'éˆ', 'parent': 'çˆ¶', 'child': 'å­', 'children': 'å­', // irregular
  'root': 'æ ¹', 'leaf': 'è‘‰', 'leave': 'è‘‰', // for 'leaves'
  'branch': 'æ”¯', 'depth': 'æ·±', 'level': 'ç´š', 'layer': 'å±¤',

  // Status/State - BASE FORMS ONLY
  'success': 'æˆ', 'successful': 'æˆly', // keep adverb form unique
  'failure': 'æ•—', 'fail': 'æ•—', 'complete': 'å®Œ', 'completion': 'å®Œtion',
  'incomplete': 'æœªå®Œ', 'pending': 'å¾…è™•ç†', 'active': 'æ´»', 'inactive': 'ä¸æ´»',
  'valid': 'æ•ˆ', 'invalid': 'ç„¡æ•ˆ', 'available': 'å¯ç”¨', 'unavailable': 'ä¸å¯ç”¨',
  'online': 'åœ¨ç·š', 'offline': 'é›¢ç·š', 'ready': 'å‚™', 'busy': 'å¿™', 'idle': 'é–’',
  'visible': 'å¯è¦‹', 'locked': 'é–', 'unlocked': 'è§£é–', 'empty': 'ç©ºç™½', 'full': 'æ»¿',
  'new': 'æ–°', 'old': 'èˆŠ', 'current': 'ç•¶å‰', 'previous': 'å‰', 'next': 'ä¸‹',
  'first': 'é¦–', 'last': 'æœ«', 'latest': 'æœ€æ–°', 'oldest': 'æœ€èˆŠ',
  'default': 'é»˜', 'custom': 'è‡ªå®š', 'local': 'æœ¬', 'remote': 'é ', 'global': 'å…¨',
  'public': 'å…¬', 'private': 'ç§', 'protected': 'è­·',
  'static': 'éœ', 'dynamic': 'å‹•', 'constant': 'æ†å®š',
  'temporary': 'è‡¨', 'permanent': 'æ°¸', 'optional': 'å¯é¸',
  'true': 'çœŸ', 'false': 'å‡',

  // Common nouns - BASE FORMS ONLY
  'code': 'ç¢¼', 'data': 'æ“š', 'information': 'è³‡è¨Š', 'result': 'æœ',
  'output': 'è¼¸å‡º', 'input': 'è¼¸å…¥', 'content': 'å…§å®¹',
  'text': 'æ–‡', 'name': 'å', 'title': 'æ¨™é¡Œ', 'label': 'æ¨™ç±¤',
  'tag': 'æ¨™', 'category': 'é¡åˆ¥', 'group': 'ç¾¤çµ„', 'size': 'å¤§å°',
  'length': 'é•·', 'total': 'ç¸½', 'sum': 'å’Œ', 'average': 'å‡',
  'maximum': 'æœ€å¤§', 'max': 'æœ€å¤§', 'minimum': 'æœ€å°', 'min': 'æœ€å°',
  'range': 'ç¯„åœ', 'limit': 'é™', 'threshold': 'é–¾', 'offset': 'åç§»',
  'position': 'ä½', 'location': 'é»', 'time': 'æ™‚', 'date': 'æ—¥',
  'timestamp': 'æ™‚æˆ³', 'duration': 'æŒçºŒ', 'project': 'å°ˆ', 'version': 'ç‰ˆ',
  'release': 'ç™¼å¸ƒ', 'issue': 'é¡Œ', 'bug': 'èŸ²', 'feature': 'åŠŸèƒ½',
  'component': 'ä»¶', 'element': 'ç´ ', 'item': 'é …', 'entry': 'æ¢',
  'entity': 'é«”', 'model': 'æ¨¡', 'schema': 'ç¶±è¦', 'template': 'æ¨¡æ¿',
  'pattern': 'æ¨¡å¼', 'design': 'è¨­è¨ˆ', 'architecture': 'æ¶æ§‹',
  'structure': 'çµæ§‹', 'style': 'æ¨£å¼', 'config': 'é…æª”',
  'configuration': 'é…æª”', 'setting': 'ç½®', 'option': 'é¸', 'preference': 'åå¥½',
  'system': 'ç³»', 'application': 'æ‡‰ç”¨', 'app': 'æ‡‰ç”¨',
  'document': 'æ–‡æª”', 'documentation': 'æ–‡æª”', 'guide': 'æŒ‡å—',
  'example': 'ä¾‹', 'sample': 'æ¨£', 'demo': 'æ¼”ç¤º',
  'problem': 'å•é¡Œ', 'solution': 'è§£æ³•', 'answer': 'ç­”', 'question': 'å•',
  'reason': 'åŸå› ', 'cause': 'èµ·å› ', 'effect': 'æ•ˆæœ', 'impact': 'éŸ¿',
  'performance': 'æ€§èƒ½', 'efficiency': 'æ•ˆç‡', 'speed': 'é€Ÿ',
  'quality': 'è³ª', 'security': 'å®‰å…¨', 'privacy': 'éš±ç§',

  // SpecMem specific - BASE FORMS ONLY
  'specmem': 'SM', 'semantic': 'èªç¾©', 'episodic': 'æƒ…ç¯€', 'procedural': 'ç¨‹åº',
  'drilldown': 'DD', 'traceback': 'è¿½è¹¤', 'conversation': 'å°è©±',
  'prompt': 'æç¤º', 'hook': 'é‰¤', 'inject': 'æ³¨',
  'compaction': 'å£“ç¸®', 'compression': 'å£“ç¸®ion', 'similarity': 'ä¼¼åº¦',
  'relevance': 'ç›¸é—œ', 'embedding': 'åµŒå…¥', 'vector': 'å‘é‡',
  'team': 'éšŠ', 'member': 'å“¡', 'agent': 'ä»£ç†',
  'context': 'ä¸Šä¸‹æ–‡', 'summary': 'æ‘˜è¦',

  // Additional common words
  'status': 'ç‹€æ…‹', 'type': 'å‹', 'following': 'å¾Œæ–‡', 'complexity': 'è¤‡é›œ',
  'significant': 'é¡¯è‘—', 'improve': 'æ”¹é€²', 'improvement': 'æ”¹é€²ment',
  'automatic': 'è‡ªå‹•', 'correct': 'æ­£ç¢º', 'whether': 'æ˜¯å¦',
  'specific': 'ç‰¹å®š', 'different': 'ä¸åŒ', 'same': 'ç›¸åŒ',
  'important': 'é‡è¦', 'necessary': 'å¿…è¦',
  };
}

// Build reverse mapping (one Chinese code â†’ one English word for decompression)
const REVERSE = {};
for (const [eng, chi] of Object.entries(CODES)) {
  // Only store base form for reverse mapping (avoid duplicates)
  if (!REVERSE[chi]) {
    REVERSE[chi] = eng;
  }
}

// COMBINE all reverse mappings and sort by length (longer first)
// This is critical - longer codes must be replaced before shorter ones
// e.g., "æ€§èƒ½" (performance) must be replaced before "èƒ½" (able to)
const ALL_REVERSE = { ...REVERSE_PHRASES, ...REVERSE };
const SORTED_ALL_REVERSE = Object.entries(ALL_REVERSE).sort((a, b) => b[0].length - a[0].length);

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// SUFFIX HANDLING - Preserve English grammatical forms automatically!
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ENGLISH MORPHOLOGY ENGINE - Handles ALL suffix patterns correctly
// Uses standalone version with embedded irregular forms (no external deps)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
let morphology;
try {
  // Try standalone version first (no external deps)
  morphology = require('./english-morphology-standalone.cjs');
} catch (e1) {
  try {
    // Fallback to full version with wink-lexicon
    morphology = require('./english-morphology.cjs');
  } catch (e2) {
    // Final fallback: no morphology
    morphology = { getBaseForm: (w, C) => ({ base: w, suffix: '' }) };
  }
}

/**
 * Extract base form and suffix using morphology engine
 * Handles: -ing, -ed, -s, -es, -er, -est, irregular forms (ran, wrote, children)
 */
function extractSuffix(word) {
  return morphology.getBaseForm(word, CODES);
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// COMPRESSION ENGINE
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Check if a character is Chinese
 */
function isChinese(char) {
  const code = char.charCodeAt(0);
  return code >= 0x4E00 && code <= 0x9FFF;
}

/**
 * Compress text with ultra-aggressive Chinese encoding
 */
function compress(text) {
  if (!text || text.length < 20) return text;

  // Preserve special content
  const preserved = [];
  let idx = 0;

  let result = text
    // Code blocks
    .replace(/```[\s\S]*?```/g, m => { preserved.push(m); return `Â§${idx++}Â§`; })
    // Inline code
    .replace(/`[^`]+`/g, m => { preserved.push(m); return `Â§${idx++}Â§`; })
    // URLs
    .replace(/https?:\/\/[^\s]+/g, m => { preserved.push(m); return `Â§${idx++}Â§`; })
    // File paths (Unix and Windows)
    .replace(/(?:\/[\w.-]+){2,}|[A-Z]:\\[\w\\.-]+/g, m => { preserved.push(m); return `Â§${idx++}Â§`; })
    // camelCase identifiers
    .replace(/\b[a-z]+(?:[A-Z][a-z]+)+\b/g, m => { preserved.push(m); return `Â§${idx++}Â§`; })
    // PascalCase identifiers
    .replace(/\b[A-Z][a-z]+(?:[A-Z][a-z]+)+\b/g, m => { preserved.push(m); return `Â§${idx++}Â§`; })
    // snake_case identifiers
    .replace(/\b[a-z]+(?:_[a-z]+)+\b/g, m => { preserved.push(m); return `Â§${idx++}Â§`; })
    // SCREAMING_SNAKE_CASE
    .replace(/\b[A-Z]+(?:_[A-Z]+)+\b/g, m => { preserved.push(m); return `Â§${idx++}Â§`; })
    // Version numbers
    .replace(/\bv?\d+\.\d+(?:\.\d+)?(?:-[\w.]+)?\b/g, m => { preserved.push(m); return `Â§${idx++}Â§`; });

  // PHASE 1: Replace phrases FIRST (highest savings)
  for (const [phrase, code] of SORTED_PHRASES) {
    const regex = new RegExp(`\\b${phrase.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')}\\b`, 'gi');
    result = result.replace(regex, code);
  }

  // PHASE 2: Compress words with ENGLISH SUFFIX PRESERVATION
  // Priority: exact match > base+suffix (server=æœ, working=å·¥ing)
  result = result.replace(/\b([a-zA-Z']+)\b/g, (match, word) => {
    const lower = word.toLowerCase();
    if (REMOVE.has(lower)) return '';

    // FIRST: Try exact match (serverâ†’æœ, databaseâ†’è³‡æ–™åº«)
    if (CODES.hasOwnProperty(lower)) return CODES[lower];

    // SECOND: Try extracting suffix (workingâ†’å·¥ing, createdâ†’å‰µed)
    const { base, suffix } = extractSuffix(word);
    if (suffix && CODES.hasOwnProperty(base)) {
      return CODES[base] + suffix;
    }

    return word; // Keep as-is if no match
  });

  // PHASE 3: Join consecutive Chinese characters (no spaces needed!)
  // This is the key to massive character savings
  result = result.replace(/([ä¸€-é¾¥])(\s+)([ä¸€-é¾¥])/g, '$1$3');

  // PHASE 4: Use micro-delimiter between Chinese and English/preserved
  result = result.replace(/([ä¸€-é¾¥])\s+([a-zA-ZÂ§])/g, `$1${MICRO_SEP}$2`);
  result = result.replace(/([a-zA-ZÂ§])\s+([ä¸€-é¾¥])/g, `$1${MICRO_SEP}$2`);

  // Clean up whitespace
  result = result
    .replace(/  +/g, ' ')
    .replace(/\n +/g, '\n')
    .replace(/ +\n/g, '\n')
    .replace(/\n\n\n+/g, '\n\n')
    .replace(/ +([.,!?;:])/g, '$1')
    .trim();

  // Restore preserved content
  for (let i = 0; i < preserved.length; i++) {
    result = result.replace(`Â§${i}Â§`, preserved[i]);
  }

  return result;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EN-INFLECTORS - Smart verb/noun conjugation for perfect decompression
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
let Inflectors;
try {
  Inflectors = require('en-inflectors').Inflectors;
} catch (e) {
  // Fallback if not installed
  Inflectors = null;
}

/**
 * Intelligently inflect a base word with a suffix marker
 * Uses en-inflectors library for accurate conjugation
 */
function inflectWord(base, suffix) {
  if (!suffix) return base;

  // Use en-inflectors if available
  if (Inflectors) {
    try {
      const inf = new Inflectors(base);
      switch (suffix) {
        case 's':
        case 'es':
          // Could be plural noun OR 3rd person verb
          // Try plural first, fallback to presentS
          const plural = inf.toPlural();
          if (plural !== base) return plural;
          return inf.toPresentS();
        case 'ed':
          return inf.toPast();
        case 'ing':
          return inf.toGerund();
        case 'er':
          // Could be comparative OR agent noun (worker)
          return base + 'er'; // Simple concat for now
        case 'est':
          return base + 'est'; // Superlative
        default:
          return base + suffix;
      }
    } catch (e) {
      // Fallback to simple concat
    }
  }

  // Fallback: smart concat (handle 'e' endings)
  if (base.endsWith('e') && (suffix === 'ed' || suffix === 'es' || suffix === 'er' || suffix === 'est')) {
    return base + suffix.slice(1);
  }
  return base + suffix;
}

/**
 * Decompress text back to English
 * CRITICAL: Uses en-inflectors for proper suffix handling
 */
function decompress(text) {
  if (!text) return text;
  let result = text;

  // Replace micro-delimiter with space
  result = result.split(MICRO_SEP).join(' ');

  // PHASE 1: Replace Chinese codes that have suffixes attached
  // Pattern: ChineseCode + EnglishSuffix â†’ properly inflected English word
  const SUFFIXES = ['tion', 'ment', 'ing', 'ed', 'er', 'est', 'es', 's', 'ly'];

  for (const [chi, eng] of SORTED_ALL_REVERSE) {
    // Try each suffix pattern (longest first for correct matching)
    for (const suf of SUFFIXES) {
      const pattern = chi + suf;
      if (result.includes(pattern)) {
        const inflected = inflectWord(eng, suf);
        result = result.split(pattern).join(` ${inflected} `);
      }
    }
    // Then replace bare Chinese codes
    if (result.includes(chi)) {
      result = result.split(chi).join(` ${eng} `);
    }
  }

  // Clean up multiple spaces and around punctuation
  result = result
    .replace(/\s+([.,!?;:)\]}])/g, '$1')  // no space before punctuation
    .replace(/([(\[{])\s+/g, '$1')        // no space after opening brackets
    .replace(/  +/g, ' ')
    .trim();

  return result;
}

/**
 * Extract semantic words (lemmatized base forms)
 * Uses the same morphology engine as compression for consistency
 */
function getSemanticWords(text) {
  const words = text.toLowerCase()
    .replace(/[^\w\s]/g, ' ')
    .split(/\s+/)
    .filter(w => w.length > 1 && !REMOVE.has(w));

  // Use morphology engine for consistent lemmatization
  return words.map(w => {
    // Try morphology engine first (consistent with compression)
    const { base } = morphology.getBaseForm(w, CODES);
    if (base !== w && CODES[base]) {
      return base;
    }

    // Fallback: simple suffix removal for words not in CODES
    // Adverb suffix
    if (w.endsWith('ally') && w.length > 6) return w.slice(0, -4);
    if (w.endsWith('ily') && w.length > 5) return w.slice(0, -3);
    if (w.endsWith('ly') && w.length > 4) return w.slice(0, -2);

    // -ing: keep as-is if no match (avoid "creat" problem)
    if (w.endsWith('ing') && w.length > 5) {
      let base = w.slice(0, -3);
      if (base.length > 2 && base[base.length-1] === base[base.length-2]) {
        base = base.slice(0, -1);
      }
      // Check if adding 'e' makes a valid word (creating â†’ create)
      if (CODES[base + 'e']) return base + 'e';
      if (CODES[base]) return base;
      return w; // Keep original if no match
    }

    // -ed: handle various cases
    if (w.endsWith('ed') && w.length > 4) {
      if (w.endsWith('ced') || w.endsWith('ged') || w.endsWith('sed') ||
          w.endsWith('ted') || w.endsWith('ved') || w.endsWith('zed')) {
        if (w.length > 5 && w[w.length-3] === w[w.length-4]) {
          return w.slice(0, -3);
        }
        return w.slice(0, -1);
      }
      return w.slice(0, -2);
    }

    // Plurals: only remove -es for specific endings (s, x, ch, sh + es)
    // Words ending in -ize take -s not -es (initialize â†’ initializes)
    if (w.length > 5) {
      if (w.endsWith('sses')) return w.slice(0, -2); // processes â†’ process
      if (w.endsWith('xes')) return w.slice(0, -2);  // fixes â†’ fix
      if (w.endsWith('ches')) return w.slice(0, -2); // teaches â†’ teach
      if (w.endsWith('shes')) return w.slice(0, -2); // pushes â†’ push
      // NOTE: -zes NOT included because -ize words take -s (initializes â†’ initialize)
    }
    // Regular -s (creates â†’ create, initializes â†’ initialize)
    if (w.endsWith('s') && !w.endsWith('ss') && w.length > 3) {
      return w.slice(0, -1);
    }

    return w;
  });
}

/**
 * Verify round-trip semantic accuracy
 */
function verifyRoundTrip(original, compressed) {
  const decompressed = decompress(compressed);

  const origWords = getSemanticWords(original);
  const decomWords = getSemanticWords(decompressed);

  if (origWords.length === 0) return { verified: true, accuracy: 1.0 };

  // Count semantic matches (using sets for unique concepts)
  const origSet = new Set(origWords);
  const decomSet = new Set(decomWords);

  let matches = 0;
  for (const word of origSet) {
    if (decomSet.has(word)) matches++;
  }

  const accuracy = matches / origSet.size;
  return { verified: accuracy >= 0.90, accuracy };
}

/**
 * Get compression statistics - CHARACTER based!
 */
function getStats(text) {
  const compressed = compress(text);
  const roundTrip = verifyRoundTrip(text, compressed);

  // CHARACTER savings (the real metric!)
  const origChars = text.length;
  const compChars = compressed.length;
  const charSavings = origChars > 0 ? ((origChars - compChars) / origChars * 100).toFixed(1) : '0.0';

  // Word savings (secondary metric)
  const origWords = text.split(/\s+/).filter(Boolean).length;
  const compWords = compressed.split(/\s+/).filter(Boolean).length;
  const wordSavings = origWords > 0 ? ((origWords - compWords) / origWords * 100).toFixed(1) : '0.0';

  return {
    originalChars: origChars,
    compressedChars: compChars,
    charSavings: charSavings + '%',
    originalWords: origWords,
    compressedWords: compWords,
    wordSavings: wordSavings + '%',
    roundTrip: {
      verified: roundTrip.verified,
      accuracy: (roundTrip.accuracy * 100).toFixed(1) + '%'
    }
  };
}

/**
 * Compress hook output with warning
 * Options:
 *   minLength: minimum text length to compress (default: 30)
 *   includeWarning: prepend compression warning (default: true)
 *   verboseWarning: use multi-line warning (default: false - uses compact single-line)
 *   flattenOutput: join lines with pipe separator instead of newlines (default: false)
 *   preserveStructure: keep original line structure (default: false)
 */
function compressHookOutput(text, options = {}) {
  const minLength = options.minLength || 30;
  const includeWarning = options.includeWarning !== false;
  // Default to compact warning (saves 200+ chars) unless explicitly verbose
  const useVerboseWarning = options.verboseWarning === true;
  // NEW: flattenOutput option to avoid newlines breaking Claude's formatting
  const flattenOutput = options.flattenOutput === true;

  if (!text || text.length < minLength) return text;

  const lines = text.split('\n');
  let anyCompressed = false;

  const compressedLines = lines.map(line => {
    if (line.length < 15) return line;
    if (line.startsWith('#')) return line;
    if (line.startsWith('```')) return line;
    if (/^\s*[-*]\s*`/.test(line)) return line;
    if (line.replace(/[^\w\s]/g, '').length < line.length * 0.4) return line;

    const compressed = compress(line);
    if (compressed !== line) anyCompressed = true;
    return compressed;
  });

  let output;
  if (flattenOutput) {
    // FLATTENED: Join with pipe separator instead of newlines
    output = compressedLines
      .map(l => l.trim())
      .filter(l => l.length > 0)
      .join(' | ');
  } else {
    // COLLAPSE WHITESPACE: Remove multiple blank lines, trim each line
    output = compressedLines
      .map(l => l.trimEnd())
      .join('\n')
      .replace(/\n{3,}/g, '\n')  // Collapse 3+ newlines to just 1
      .trim();
  }

  if (includeWarning && anyCompressed) {
    // Use compact (single-line) warning by default
    const warning = useVerboseWarning ? COMPRESSION_WARNING : COMPACT_WARNING;
    return warning + output;
  }
  return output;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EXPORTS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
module.exports = {
  compress,
  decompress,
  compressHookOutput,
  verifyRoundTrip,
  getStats,
  getSemanticWords, // For debugging
  CODES,
  REVERSE,
  REMOVE,
  PHRASES,
  REVERSE_PHRASES,
  COMPRESSION_WARNING,
  COMPACT_WARNING,
  MICRO_SEP
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// CLI TEST
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if (require.main === module) {
  const testText = `
The function initializes the database connection and creates a new session.
It will validate the user authentication token and check permissions.
If the request is valid, it returns the response with success status.
The server processes the query and returns the filtered results.
This module handles error logging and provides debug information.
The system should automatically save all changes to the storage.
In order to make sure that the code works correctly, we need to test it.
The following example shows how to use the API endpoint.
Due to the complexity of the problem, we have to implement a custom solution.
As a result, the performance has been significantly improved.
  `.trim();

  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('TOKEN COMPRESSOR v6.0 - ULTRA COMPRESSION TEST');
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('\nğŸ“„ ORIGINAL:');
  console.log(testText);
  console.log(`\n   Characters: ${testText.length}`);
  console.log(`   Words: ${testText.split(/\s+/).length}`);
  console.log('\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');

  const compressed = compress(testText);
  console.log('\nğŸ—œï¸ COMPRESSED:');
  console.log(compressed);
  console.log(`\n   Characters: ${compressed.length}`);
  console.log(`   Words: ${compressed.split(/\s+/).filter(Boolean).length}`);
  console.log('\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');

  const decompressed = decompress(compressed);
  console.log('\nğŸ”„ DECOMPRESSED:');
  console.log(decompressed);
  console.log('\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');

  const stats = getStats(testText);
  console.log('\nğŸ“Š RESULTS:');
  console.log(`   ğŸ“ CHARACTER Savings: ${stats.charSavings} â† PRIMARY METRIC`);
  console.log(`   ğŸ“ Word Savings: ${stats.wordSavings}`);
  console.log(`   ğŸ”„ Semantic Accuracy: ${stats.roundTrip.accuracy}`);
  console.log(`   âœ… Verified: ${stats.roundTrip.verified ? 'YES!' : 'NO'}`);
  console.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

  // Show phrase compression demo
  console.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('PHRASE COMPRESSION DEMO:');
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  const phrases = [
    'in order to create a new function',
    'the following example shows how to use',
    'as a result of the change in performance',
    'due to the complexity of the problem',
    'based on the configuration settings',
  ];
  for (const p of phrases) {
    const c = compress(p);
    const pct = ((p.length - c.length) / p.length * 100).toFixed(0);
    console.log(`"${p}"`);
    console.log(`  â†’ "${c}" (${pct}% smaller)`);
    console.log();
  }
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
}
